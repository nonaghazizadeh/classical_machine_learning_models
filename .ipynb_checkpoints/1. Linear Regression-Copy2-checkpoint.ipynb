{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16adc323",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Nona Ghazizadeh<br>\n",
    "   **Student ID**: 98171007<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585264a",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387d3a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./startups.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['Profit'].values.tolist())\n",
    "y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0669d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Profit\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d236e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend California New York Florida\n",
       "0  165349.20       136897.80        471784.10          0        1       0\n",
       "1  162597.70       151377.59        443898.53          1        0       0\n",
       "2  153441.51       101145.55        407934.54          0        0       1\n",
       "3  144372.41       118671.85        383199.62          0        1       0\n",
       "4  142107.34        91391.77        366168.42          0        0       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(to_replace=[\"California\",\"New York\", \"Florida\"], value=[1,2,3])\n",
    "\n",
    "df[\"California\"] = df.iloc[:, 3]\n",
    "df[\"New York\"] = df.iloc[:,3]\n",
    "df[\"Florida\"] = df.iloc[:,3]\n",
    "\n",
    "df.loc[df[\"California\"]!=\"California\", \"California\"] = 0\n",
    "df.loc[df[\"California\"]==\"California\", \"California\"] = 1\n",
    "\n",
    "df.loc[df[\"New York\"]!=\"New York\", \"New York\"] = 0\n",
    "df.loc[df[\"New York\"]==\"New York\", \"New York\"] = 1\n",
    "\n",
    "df.loc[df[\"Florida\"]!=\"Florida\", \"Florida\"] = 0\n",
    "df.loc[df[\"Florida\"]==\"Florida\", \"Florida\"] = 1\n",
    "\n",
    "df.drop([\"State\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling_for_independent_variable(variables):\n",
    "    for i in range(variables.shape[1]-3):\n",
    "        variables[:,i] = (variables[:,i] - int(np.mean(variables[:,i])))/np.std(variables[:,i])\n",
    "    return variables\n",
    "    \n",
    "def feature_scaling_for_dependent_variable(variables):\n",
    "    variables = (variables - int(np.mean(variables)))/np.std(variables)\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d959e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.values.tolist())\n",
    "x = feature_scaling_for_independent_variable(x)\n",
    "x = np.concatenate((x,np.ones((50,1))), axis = 1)\n",
    "\n",
    "y = feature_scaling_for_dependent_variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5f4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a52bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y,test_size=0.2,random_state=0):\n",
    "    np.random.seed(random_state)                 \n",
    "    indices = np.random.permutation(len(x))       \n",
    "    data_test_size = int(x.shape[0] * test_size)  \n",
    "\n",
    "    train_indices = indices[data_test_size:]\n",
    "    test_indices = indices[:data_test_size]\n",
    "    x_train = x[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    x_test = x[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b80cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = split_data(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c771220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, learning_rate, iteration, regularization):\n",
    "        self.m = None\n",
    "        self.n = None\n",
    "        self.w = None\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.it = iteration\n",
    "        self.regularization = regularization\n",
    "        \n",
    "    def cost_function(self, y, y_pred):\n",
    "        if self.regularization == None:\n",
    "            return (1 / (2 * self.m)) * np.sum(np.square(y_pred - y))\n",
    "        else:\n",
    "            return (1 / (2 * self.m)) * np.sum(np.square(y_pred - y)) + self.regularization(self.w)\n",
    "    \n",
    "    def hypothesis(self, weights, x):\n",
    "        return np.dot(x, weights)\n",
    "    \n",
    "    def train(self, x, y):     \n",
    "        self.m = x.shape[0]\n",
    "        self.n = x.shape[1]\n",
    "        self.w = np.zeros((self.n , 1))\n",
    "        \n",
    "        for it in range(1, self.it + 1):\n",
    "            y_pred = self.hypothesis(self.w, x)\n",
    "            cost = self.cost_function(y, y_pred)\n",
    "            if self.regularization == None:\n",
    "                dw = (1 / self.m) * np.dot(x.T, (y_pred - y))\n",
    "            else:\n",
    "                dw = (1 / self.m) * np.dot(x.T, (y_pred - y)) + self.regularization.derivation(self.w)\n",
    "\n",
    "            self.w = self.w - self.lr * dw\n",
    "            \n",
    "            if it % 100 == 0:\n",
    "                print(\"The cost function for the iteration {} is {}\".format(it, cost))\n",
    "   \n",
    "    def predict(self, x):\n",
    "        y_pred = self.hypothesis(self.w, x)\n",
    "        return y_pred\n",
    "    \n",
    "    def mse_loss(self, y, y_pred):\n",
    "        return np.sum(np.square(y - y_pred).ravel()) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "865c7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1_regularization:\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.lamda * np.sum(np.abs(weights))\n",
    "    \n",
    "    def derivation(self, weights):\n",
    "        return self.lamda * np.sign(weights)\n",
    "    \n",
    "class l2_regularization:\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.lamda * np.sum(np.square(weights))\n",
    "    \n",
    "    def derivation(self, weights):\n",
    "        return self.lamda * 2 * (weights)\n",
    "    \n",
    "class l1_l2_regularization:\n",
    "    \n",
    "    def __init__(self, lamda = 0.1, l_ratio = 0.5):\n",
    "        self.lamda = lamda \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        l1_contribution = self.l_ratio * self.lamda * np.sum(np.abs(weights))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.lamda * 0.5 * np.sum(np.square(weights))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, weights):\n",
    "        l1_derivation = self.lamda * self.l_ratio * np.sign(weights)\n",
    "        l2_derivation = self.lamda * (1 - self.l_ratio) * weights\n",
    "        return (l1_derivation + l2_derivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd340dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(Regression):\n",
    "    \n",
    "    def __init__(self, lamda, learning_rate, iteration):\n",
    "        self.regularization = l1_regularization(lamda)\n",
    "        super(LassoRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "\n",
    "    def train(self, x, y):\n",
    "        return super(LassoRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(LassoRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e637fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(Regression):\n",
    "\n",
    "    def __init__(self, lamda, learning_rate, iteration):\n",
    "        self.regularization = l2_regularization(lamda)\n",
    "        super(RidgeRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "\n",
    "    def train(self, x, y):\n",
    "        return super(RidgeRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(RidgeRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe789085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticNetRegression(Regression):\n",
    "\n",
    "    def __init__(self, lamda, l_ratio, learning_rate, iteration):\n",
    "        self.regularization = l1_l2_regularization(lamda,l_ratio)\n",
    "        super(ElasticNetRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        return super(ElasticNetRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(ElasticNetRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bcc63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost function for the iteration 100 is 0.026064362614481296\n",
      "The cost function for the iteration 200 is 0.02562713776249019\n",
      "The cost function for the iteration 300 is 0.025617704881025546\n",
      "The cost function for the iteration 400 is 0.025617487037552192\n",
      "The cost function for the iteration 500 is 0.025617481979829812\n",
      "The cost function for the iteration 600 is 0.02561748186235474\n",
      "The cost function for the iteration 700 is 0.02561748185962607\n",
      "The cost function for the iteration 800 is 0.025617481859562686\n",
      "The cost function for the iteration 900 is 0.025617481859561215\n",
      "The cost function for the iteration 1000 is 0.025617481859561177\n",
      "The linear regression MSE loss for the train data is:  0.05123496371912236\n",
      "The linear regression MSE loss for the test data is:  0.052448372024488696\n"
     ]
    }
   ],
   "source": [
    "linear_reg_param = {\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000,\n",
    "    \"regularization\": None   \n",
    "}\n",
    "linear_reg = Regression(**linear_reg_param)\n",
    "linear_reg.train(x_train, y_train) \n",
    "linear_reg_y_pred = linear_reg.predict(x_train)\n",
    "linear_reg_score = linear_reg.mse_loss(y_train, linear_reg_y_pred)\n",
    "print(\"The linear regression MSE loss for the train data is: \", linear_reg_score)\n",
    "\n",
    "linear_reg_y_pred_test = linear_reg.predict(x_test)\n",
    "linear_reg_test_score = linear_reg.mse_loss(y_test, linear_reg_y_pred_test)\n",
    "print(\"The linear regression MSE loss for the test data is: \", linear_reg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46b3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost function for the iteration 100 is 0.12488064501374983\n",
      "The cost function for the iteration 200 is 0.12310010621243461\n",
      "The cost function for the iteration 300 is 0.12335441509978905\n",
      "The cost function for the iteration 400 is 0.12294257248221901\n",
      "The cost function for the iteration 500 is 0.12269995753169363\n",
      "The cost function for the iteration 600 is 0.12306318396023232\n",
      "The cost function for the iteration 700 is 0.12253585910768301\n",
      "The cost function for the iteration 800 is 0.12285247026185928\n",
      "The cost function for the iteration 900 is 0.12331832464372164\n",
      "The cost function for the iteration 1000 is 0.12244764541327252\n",
      "The lasso regresion MSE loss for the train data is:  0.06306048717682113\n",
      "The lasso regresion MSE loss for the test data is:  0.05100980844230587\n"
     ]
    }
   ],
   "source": [
    "lasso_param = {\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "lasso_reg = LassoRegression(**lasso_param)\n",
    "lasso_reg.train(x_train, y_train) \n",
    "lasso_y_pred = lasso_reg.predict(x_train)\n",
    "lasso_score = lasso_reg.mse_loss(y_train, lasso_y_pred)\n",
    "print(\"The lasso regresion MSE loss for the train data is: \", lasso_score)\n",
    "\n",
    "lasso_y_pred_test = lasso_reg.predict(x_test)\n",
    "lasso_test_score = lasso_reg.mse_loss(y_test, lasso_y_pred_test)\n",
    "print(\"The lasso regresion MSE loss for the test data is: \", lasso_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718c2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost function for the iteration 100 is 0.08564596375003528\n",
      "The cost function for the iteration 200 is 0.0856422543261855\n",
      "The cost function for the iteration 300 is 0.08564225303993578\n",
      "The cost function for the iteration 400 is 0.0856422530394526\n",
      "The cost function for the iteration 500 is 0.08564225303945242\n",
      "The cost function for the iteration 600 is 0.08564225303945242\n",
      "The cost function for the iteration 700 is 0.08564225303945243\n",
      "The cost function for the iteration 800 is 0.08564225303945243\n",
      "The cost function for the iteration 900 is 0.08564225303945243\n",
      "The cost function for the iteration 1000 is 0.08564225303945243\n",
      "The ridge regresion MSE loss for the train data is:  0.07470067390396201\n",
      "The ridge regresion MSE loss for the test data is:  0.1150218086768257\n"
     ]
    }
   ],
   "source": [
    "ridge_param = {\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "ridge_reg = RidgeRegression(**ridge_param)\n",
    "ridge_reg.train(x_train,y_train) \n",
    "ridge_y_pred = ridge_reg.predict(x_train)\n",
    "ridge_score = ridge_reg.mse_loss(y_train, ridge_y_pred)\n",
    "print(\"The ridge regresion MSE loss for the train data is: \", ridge_score)\n",
    "\n",
    "ridge_y_pred_test = ridge_reg.predict(x_test)\n",
    "ridge_test_score = ridge_reg.mse_loss(y_test, ridge_y_pred_test)\n",
    "print(\"The ridge regresion MSE loss for the test data is: \", ridge_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d5103b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost function for the iteration 100 is 0.09260078495786978\n",
      "The cost function for the iteration 200 is 0.0926040540775132\n",
      "The cost function for the iteration 300 is 0.09262837951654866\n",
      "The cost function for the iteration 400 is 0.09255771844703764\n",
      "The cost function for the iteration 500 is 0.09264042540753988\n",
      "The cost function for the iteration 600 is 0.09247854926600887\n",
      "The cost function for the iteration 700 is 0.09234827814149547\n",
      "The cost function for the iteration 800 is 0.09251564218534528\n",
      "The cost function for the iteration 900 is 0.09249473241163614\n",
      "The cost function for the iteration 1000 is 0.09239437383820041\n",
      "The elastic net MSE loss of the train data is:  0.05989135533483585\n",
      "The elastic net MSE loss of the test data is:  0.05139510943363168\n"
     ]
    }
   ],
   "source": [
    "elastic_net_param = {\n",
    "    \"l_ratio\" : 0.5,\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "elastic_net_reg = ElasticNetRegression(**elastic_net_param)\n",
    "elastic_net_reg.train(x_train, y_train) \n",
    "elastic_net_y_pred = elastic_net_reg.predict(x_train)\n",
    "elastic_net_score = elastic_net_reg.mse_loss(y_train, elastic_net_y_pred)\n",
    "print(\"The elastic net MSE loss of the train data is: \", elastic_net_score)\n",
    "\n",
    "elastic_net_y_pred_test = elastic_net_reg.predict(x_test)\n",
    "elastic_net_test_score = elastic_net_reg.mse_loss(y_test, elastic_net_y_pred_test)\n",
    "print(\"The elastic net MSE loss of the test data is: \", elastic_net_test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
