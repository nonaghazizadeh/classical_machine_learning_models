{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16adc323",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Nona Ghazizadeh<br>\n",
    "   **Student ID**: 98171007<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585264a",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b72ee7",
   "metadata": {},
   "source": [
    "In this notebook the dataset that we choose is datsets for startups, it has features like R&D spend, administration, marketing spend and state after that from these features we can get profit of the startups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387d3a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./startups.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4329625",
   "metadata": {},
   "source": [
    "In the code below we separate the independent and dependent features, and take out dependent feature which is profit freature in our dataset and then we reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce45d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['Profit'].values.tolist())\n",
    "y = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf99964",
   "metadata": {},
   "source": [
    "In the code below we remove profit column, hence our dataset has only independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0669d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Profit\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa87e35",
   "metadata": {},
   "source": [
    "In the code below we want to handke the feauter \"State\" with the one hor encoding. At first we replace California by 1, New York by 2, Florida by 3. \n",
    "</br>\n",
    "After that we create 3 columns with the respective State names. Then, we replace the values of the particular State of the particular State column by one and others by zero. This means, in the column California, we will replace all the California values by 1 and the values New York, Florida by zero.\n",
    "</br>\n",
    "After this, we can drop our original column \"State\".\n",
    "</br>\n",
    "ps: There is no hierarchy relation between the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d236e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>California</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend California New York Florida\n",
       "0  165349.20       136897.80        471784.10          0        1       0\n",
       "1  162597.70       151377.59        443898.53          1        0       0\n",
       "2  153441.51       101145.55        407934.54          0        0       1\n",
       "3  144372.41       118671.85        383199.62          0        1       0\n",
       "4  142107.34        91391.77        366168.42          0        0       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(to_replace=[\"California\",\"New York\", \"Florida\"], value=[1,2,3])\n",
    "\n",
    "df[\"California\"] = df.iloc[:, 3]\n",
    "df[\"New York\"] = df.iloc[:,3]\n",
    "df[\"Florida\"] = df.iloc[:,3]\n",
    "\n",
    "df.loc[df[\"California\"]!=\"California\", \"California\"] = 0\n",
    "df.loc[df[\"California\"]==\"California\", \"California\"] = 1\n",
    "\n",
    "df.loc[df[\"New York\"]!=\"New York\", \"New York\"] = 0\n",
    "df.loc[df[\"New York\"]==\"New York\", \"New York\"] = 1\n",
    "\n",
    "df.loc[df[\"Florida\"]!=\"Florida\", \"Florida\"] = 0\n",
    "df.loc[df[\"Florida\"]==\"Florida\", \"Florida\"] = 1\n",
    "\n",
    "df.drop([\"State\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b40e23",
   "metadata": {},
   "source": [
    "In the code below we define two methods that they do feature scaling, one of them is for independent variables that means for our X any the other one is for dependent variables means for our Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960b90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling_for_independent_variable(variables):\n",
    "    for i in range(variables.shape[1]-3):\n",
    "        variables[:,i] = (variables[:,i] - int(np.mean(variables[:,i])))/np.std(variables[:,i])\n",
    "    return variables\n",
    "    \n",
    "def feature_scaling_for_dependent_variable(variables):\n",
    "    variables = (variables - int(np.mean(variables)))/np.std(variables)\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e1ce6",
   "metadata": {},
   "source": [
    "In the code below we use methods that we define previously to perfom feature scaling and also we add the feature X0 = 1 for our bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d959e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df.values.tolist())\n",
    "x = feature_scaling_for_independent_variable(x)\n",
    "x = np.concatenate((x,np.ones((50, 1))), axis = 1)\n",
    "\n",
    "y = feature_scaling_for_dependent_variable(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e22b49",
   "metadata": {},
   "source": [
    "In the next two code blocks at first we define a fucntion for spliting our dataset to train and test and in the next code block we split our data using thsi function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a52bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, test_size=0.2, random_state=0):\n",
    "    np.random.seed(random_state)                 \n",
    "    indices = np.random.permutation(len(x))       \n",
    "    data_test_size = int(x.shape[0] * test_size)  \n",
    "\n",
    "    train_indices = indices[data_test_size:]\n",
    "    test_indices = indices[:data_test_size]\n",
    "    x_train = x[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    x_test = x[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b80cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = split_data(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c97850",
   "metadata": {},
   "source": [
    "In the code below we define our common regression class.\n",
    "</br>\n",
    "Parameters for regression class are learning_rate that a samll value needed for gradient decent, iteration that is the number of training iteration and regularization which will be set to None for linear regression, l1 for lasso regression , l2 for ridge regression and l1_l2 for elastic net.\n",
    "</br>\n",
    "The cost function is based on the formula we have, if our regularization is equal to None it means that we don't have any regularization term due to our method that is linear regression but in the other methods we add our regularization term.\n",
    "</br>\n",
    "The hypothesis function is based on the formula which is X.w + bias and if we add 1 to our x we don't need any bias term,\n",
    "</br>\n",
    "In the train function, m is the number of training samples, n is the number of features and w is our weights that we set initial weights for it. In the for loop in this function we do these steps:\n",
    "<ol>\n",
    "    <li>\n",
    "         Find the predicted value through the hypothesis.\n",
    "    </li>\n",
    "    <li>\n",
    "         Find the Cost function value.\n",
    "    </li>\n",
    "    <li>\n",
    "         Find the derivation of weights.\n",
    "    </li>\n",
    "    <li>\n",
    "         Apply Gradient Decent.\n",
    "    </li>\n",
    "</ol> \n",
    "The predict function predicts y for given X.\n",
    "</br>\n",
    "The mse_loss function calculate loss based on the formula for mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c771220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, learning_rate, iteration, regularization):\n",
    "        self.m = None\n",
    "        self.n = None\n",
    "        self.w = None\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.it = iteration\n",
    "        self.regularization = regularization\n",
    "        \n",
    "    def cost_function(self, y, y_pred):\n",
    "        if self.regularization == None:\n",
    "            return (1 / (2 * self.m)) * np.sum(np.square(y_pred - y))\n",
    "        else:\n",
    "            return (1 / (2 * self.m)) * np.sum(np.square(y_pred - y)) + self.regularization(self.w)\n",
    "    \n",
    "    def hypothesis(self, weights, x):\n",
    "        return np.dot(x, weights)\n",
    "    \n",
    "    def train(self, x, y):     \n",
    "        self.m = x.shape[0]\n",
    "        self.n = x.shape[1]\n",
    "        self.w = np.zeros((self.n , 1))\n",
    "        \n",
    "        for it in range(1, self.it + 1):\n",
    "            y_pred = self.hypothesis(self.w, x)\n",
    "            cost = self.cost_function(y, y_pred)\n",
    "            if self.regularization == None:\n",
    "                dw = (1 / self.m) * np.dot(x.T, (y_pred - y))\n",
    "            else:\n",
    "                dw = (1 / self.m) * np.dot(x.T, (y_pred - y)) + self.regularization.derivation(self.w)\n",
    "\n",
    "            self.w = self.w - self.lr * dw\n",
    "   \n",
    "    def predict(self, x):\n",
    "        y_pred = self.hypothesis(self.w, x)\n",
    "        return y_pred\n",
    "    \n",
    "    def mse_loss(self, y, y_pred):\n",
    "        return np.sum(np.square(y - y_pred).ravel()) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56739cfe",
   "metadata": {},
   "source": [
    "In the code below we create the regularization class we want\n",
    "</br>\n",
    "l1_regularization for lasso regression.\n",
    "</br>\n",
    "l2_regularization for ridge regression.\n",
    "</br>\n",
    "l1_l2_regularization for elastic net regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865c7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1_regularization:\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.lamda * np.sum(np.abs(weights))\n",
    "    \n",
    "    def derivation(self, weights):\n",
    "        return self.lamda * np.sign(weights)\n",
    "    \n",
    "class l2_regularization:\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.lamda * np.sum(np.square(weights))\n",
    "    \n",
    "    def derivation(self, weights):\n",
    "        return self.lamda * 2 * (weights)\n",
    "    \n",
    "class l1_l2_regularization:\n",
    "    \n",
    "    def __init__(self, lamda = 0.1, l_ratio = 0.5):\n",
    "        self.lamda = lamda \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        l1_contribution = self.l_ratio * self.lamda * np.sum(np.abs(weights))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.lamda * 0.5 * np.sum(np.square(weights))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, weights):\n",
    "        l1_derivation = self.lamda * self.l_ratio * np.sign(weights)\n",
    "        l2_derivation = self.lamda * (1 - self.l_ratio) * weights\n",
    "        return (l1_derivation + l2_derivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43315399",
   "metadata": {},
   "source": [
    "In the code below we implement our lasso regression class. (we use created l1 regualarization class). At first we define the hyperparameters we are going to use in this model, lamda is our regularization factor, learning_rate is a samll value needed for gradient decent and iteration is the number of training iteration\n",
    "</br> \n",
    "For train and predict function we use train and predict implemented in the common regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cd340dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(Regression):\n",
    "    \n",
    "    def __init__(self, lamda, learning_rate, iteration):\n",
    "        self.regularization = l1_regularization(lamda)\n",
    "        super(LassoRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "\n",
    "    def train(self, x, y):\n",
    "        return super(LassoRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(LassoRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1401344",
   "metadata": {},
   "source": [
    "In the code below we implement our lasso regression class. (we use created l2 regualarization class). At first we define the hyperparameters we are going to use in this model, lamda is our regularization factor, learning_rate is a samll value needed for gradient decent and iteration is the number of training iteration\n",
    "</br> \n",
    "For train and predict function we use train and predict implemented in the common regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e637fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(Regression):\n",
    "\n",
    "    def __init__(self, lamda, learning_rate, iteration):\n",
    "        self.regularization = l2_regularization(lamda)\n",
    "        super(RidgeRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "\n",
    "    def train(self, x, y):\n",
    "        return super(RidgeRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(RidgeRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd80674",
   "metadata": {},
   "source": [
    "In the code below we implement our lasso regression class. (we use created l1_l2 regualarization class). At first we define the hyperparameters we are going to use in this model, lamda is our regularization factor, l_ratio is the ratio between lasso and ridge regression, learning_rate is a samll value needed for gradient decent and iteration is the number of training iteration\n",
    "</br> \n",
    "For train and predict function we use train and predict implemented in the common regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe789085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticNetRegression(Regression):\n",
    "\n",
    "    def __init__(self, lamda, l_ratio, learning_rate, iteration):\n",
    "        self.regularization = l1_l2_regularization(lamda,l_ratio)\n",
    "        super(ElasticNetRegression, self).__init__(learning_rate, iteration, self.regularization)\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        return super(ElasticNetRegression, self).train(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return super(ElasticNetRegression, self).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19f97e",
   "metadata": {},
   "source": [
    "In the next four code blocks we define our parameters, train our model, then we predict and after that we calculate mse loss. (first method is linear regression, second method is lasso regression, third method is ridge regression and fourth method is elastic net regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bcc63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear regression MSE loss for the test data is:  0.052448372024488696\n"
     ]
    }
   ],
   "source": [
    "linear_reg_param = {\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000,\n",
    "    \"regularization\": None   \n",
    "}\n",
    "linear_reg = Regression(**linear_reg_param)\n",
    "linear_reg.train(x_train, y_train) \n",
    "\n",
    "linear_reg_y_pred_test = linear_reg.predict(x_test)\n",
    "linear_reg_test_score = linear_reg.mse_loss(y_test, linear_reg_y_pred_test)\n",
    "print(\"The linear regression MSE loss for the test data is: \", linear_reg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f46b3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lasso regresion MSE loss for the test data is:  0.05100980844230587\n"
     ]
    }
   ],
   "source": [
    "lasso_param = {\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "lasso_reg = LassoRegression(**lasso_param)\n",
    "lasso_reg.train(x_train, y_train) \n",
    "lasso_y_pred = lasso_reg.predict(x_train)\n",
    "\n",
    "lasso_y_pred_test = lasso_reg.predict(x_test)\n",
    "lasso_test_score = lasso_reg.mse_loss(y_test, lasso_y_pred_test)\n",
    "print(\"The lasso regresion MSE loss for the test data is: \", lasso_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718c2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ridge regresion MSE loss for the test data is:  0.1150218086768257\n"
     ]
    }
   ],
   "source": [
    "ridge_param = {\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "ridge_reg = RidgeRegression(**ridge_param)\n",
    "ridge_reg.train(x_train,y_train) \n",
    "ridge_y_pred = ridge_reg.predict(x_train)\n",
    "\n",
    "ridge_y_pred_test = ridge_reg.predict(x_test)\n",
    "ridge_test_score = ridge_reg.mse_loss(y_test, ridge_y_pred_test)\n",
    "print(\"The ridge regresion MSE loss for the test data is: \", ridge_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d5103b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elastic net MSE loss of the test data is:  0.05139510943363168\n"
     ]
    }
   ],
   "source": [
    "elastic_net_param = {\n",
    "    \"l_ratio\" : 0.5,\n",
    "    \"lamda\" : 0.1,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"iteration\" : 1000\n",
    "}\n",
    "elastic_net_reg = ElasticNetRegression(**elastic_net_param)\n",
    "elastic_net_reg.train(x_train, y_train) \n",
    "elastic_net_y_pred = elastic_net_reg.predict(x_train)\n",
    "\n",
    "elastic_net_y_pred_test = elastic_net_reg.predict(x_test)\n",
    "elastic_net_test_score = elastic_net_reg.mse_loss(y_test, elastic_net_y_pred_test)\n",
    "print(\"The elastic net MSE loss of the test data is: \", elastic_net_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c284d9b3",
   "metadata": {},
   "source": [
    "As we can see for mse loss in the four methods, lasso regression is the best method, then elastic net regression is better that the others, after that linear regression and at the end the ridge regression is good by comparing their mse loss we can get the order below (from the best one to the worst one):\n",
    "<ol>\n",
    "    <li>\n",
    "        Lasso Regression\n",
    "    </li>\n",
    "    <li>\n",
    "        Elastic Net Regression\n",
    "    </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
